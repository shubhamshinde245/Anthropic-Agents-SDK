{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e242c72",
   "metadata": {},
   "source": [
    "Importing utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b00aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# load environment variable\n",
    "load_dotenv()\n",
    "\n",
    "# automatically looks for an \"ANTHROPIC_API_KEY\" environment variable\n",
    "client = Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59b2e7",
   "metadata": {},
   "source": [
    "Simple call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_assistant_log = []\n",
    "conversation_history = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"Conversation ended.\")\n",
    "        break\n",
    "\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=conversation_history,\n",
    "        system_prompt=\"You are a helpful assistant that can answer questions and help with tasks.\",\n",
    "        max_tokens=500,\n",
    "        stop_sequences=[],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    assistant_response = response.content[0].text\n",
    "    print(f\"Assistant: {assistant_response}\")\n",
    "\n",
    "    # log the assistant response\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    conversation_assistant_log.append(f\"Assistant: {assistant_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d93166",
   "metadata": {},
   "source": [
    "Excercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "def generate_questions(topic=\"AI\", number_of_questions=3):\n",
    "    questions = []\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Based on the topic '{topic}', can you generate {number_of_questions}question for me? Only respond with the question, no other text. Generate a number list of questions\",\n",
    "            }\n",
    "        ],\n",
    "        system=\"You are a helpful assistant that can answer questions and help with tasks.\",\n",
    "        max_tokens=500,\n",
    "        stop_sequences=[\"4\"],\n",
    "        stream=True\n",
    "    )\n",
    "    assistant_response = response.content[0].text\n",
    "    questions.append(assistant_response)\n",
    "    return questions\n",
    "\n",
    "pprint.pprint(generate_questions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fb852",
   "metadata": {},
   "source": [
    "Streaming 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measuring_ttft_streming():\n",
    "    stream = client.messages.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How do large language models work?\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=200,\n",
    "        temperature=0,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    for event in stream:\n",
    "        if event.type == \"message_start\":\n",
    "            print(\"Input tokens :\",event.message.usage.input_tokens, flush=True)\n",
    "        elif event.type == \"content_block_delta\":\n",
    "            print(event.delta.text, end=\"\", flush=True)\n",
    "        elif event.type == \"message_delta\":\n",
    "            print(\"\\n Output tokens:\",event.usage.output_tokens, flush= True)\n",
    "\n",
    "measuring_ttft_streming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc412c7",
   "metadata": {},
   "source": [
    "Streaming with helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AsyncAnthropic\n",
    "\n",
    "client = AsyncAnthropic()\n",
    "\n",
    "\n",
    "async def streaming_with_helpers():\n",
    "\n",
    "    conversation_history = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User :\")\n",
    "\n",
    "        if user_input.lower() == \"quit\":\n",
    "            print(\"Conversation Ended\")\n",
    "            return conversation_history\n",
    "\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        async with client.messages.stream(\n",
    "            model=\"claude-3-5-haiku-20241022\", max_tokens=200, messages=conversation_history\n",
    "        ) as stream:\n",
    "            async for text in stream.text_stream:\n",
    "                print(text, end=\"\", flush=True)\n",
    "\n",
    "        assistant_final_response = await stream.get_final_message()\n",
    "        assistant_text_response = assistant_final_response.content[0].text\n",
    "\n",
    "        conversation_history.append(\n",
    "            {\"role\": \"assistant\", \"content\": assistant_text_response}\n",
    "        )\n",
    "\n",
    "        print(\"\\nconversation_history \\n\", conversation_history)\n",
    "\n",
    "\n",
    "await streaming_with_helpers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac973bf",
   "metadata": {},
   "source": [
    "Async Chat with color coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AsyncAnthropic, AsyncMessageStream\n",
    "\n",
    "client = AsyncAnthropic()\n",
    "\n",
    "# ANSI color codes\n",
    "BLUE = \"\\033[94m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "async def streaming_with_helpers():\n",
    "\n",
    "    conversation_history = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User :\")\n",
    "        print(f\"{BLUE}User : {RESET}{user_input}\")\n",
    "\n",
    "        if user_input.lower() == \"quit\":\n",
    "            print(\"Conversation Ended\")\n",
    "            return conversation_history\n",
    "\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        async with client.messages.stream(\n",
    "            model=\"claude-3-5-haiku-20241022\",\n",
    "            max_tokens=200,\n",
    "            messages=conversation_history,\n",
    "        ) as stream:\n",
    "            async for text in stream.text_stream:\n",
    "                print(f\"{GREEN}{text}\", end=\"\", flush=True)\n",
    "\n",
    "        assistant_final_response = await stream.get_final_message()\n",
    "        assistant_text_response = assistant_final_response.content[0].text\n",
    "\n",
    "        conversation_history.append(\n",
    "            {\"role\": \"assistant\", \"content\": assistant_text_response}\n",
    "        )\n",
    "\n",
    "        print(\"\\nconversation_history \\n\", conversation_history)\n",
    "\n",
    "\n",
    "await streaming_with_helpers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d58af1",
   "metadata": {},
   "source": [
    "Async with MySteam custom output events ( source code does not work )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pasted code block does not work ( probably depricated ) Source : https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/05_Streaming.ipynb\n",
    "\n",
    "from anthropic import AsyncAnthropic, AsyncMessageStream\n",
    "\n",
    "client = AsyncAnthropic()\n",
    "\n",
    "green = \"\\033[32m\"\n",
    "reset = \"\\033[0m\"\n",
    "\n",
    "\n",
    "class MyStream(AsyncMessageStream):\n",
    "    async def on_text(self, text, snapshot):\n",
    "        # This runs only on text delta stream messages\n",
    "        print(\n",
    "            green + text + reset, flush=True\n",
    "        )  # model generated content is printed in green\n",
    "\n",
    "    async def on_stream_event(self, event):\n",
    "        # This runs on any stream event\n",
    "        print(\"on_event fired:\", event.type)\n",
    "\n",
    "\n",
    "async def streaming_events_demo():\n",
    "    async with client.messages.stream(\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Generate a 5-word poem\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        event_handler=MyStream,\n",
    "    ) as stream:\n",
    "        # Get the final accumulated message, after the stream is exhausted\n",
    "        message = await stream.get_final_message()\n",
    "        print(\"accumulated final message: \", message.to_json())\n",
    "\n",
    "\n",
    "await streaming_events_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a0880",
   "metadata": {},
   "source": [
    "Prompting with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0af714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "\n",
    "\n",
    "def create_image_message(image_path):\n",
    "    # Open the image file in \"read binary\" mode\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # Read the contents of the image as a bytes object\n",
    "        binary_data = image_file.read()\n",
    "\n",
    "    # Encode the binary data using Base64 encoding\n",
    "    base64_encoded_data = base64.b64encode(binary_data)\n",
    "\n",
    "    # Decode base64_encoded_data from bytes to a string\n",
    "    base64_string = base64_encoded_data.decode(\"utf-8\")\n",
    "\n",
    "    # Get the MIME type of the image based on its file extension\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "\n",
    "    # Create the image block\n",
    "    image_block = {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": {\"type\": \"base64\", \"media_type\": mime_type, \"data\": base64_string},\n",
    "    }\n",
    "\n",
    "    return image_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Image 1\"},\n",
    "            create_image_message(\"./test_image.jpeg\"),\n",
    "            {\"type\": \"text\", \"text\": \"Where might I find this in the world?\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-haiku-4-5-20251001\",\n",
    "    max_tokens=300,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[0].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.usage.input_tokens, response.usage.output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661e17d",
   "metadata": {},
   "source": [
    "Image from Web (  unable to run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a281434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import httpx\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Church_of_light.jpg/1599px-Church_of_light.jpg\"\n",
    "image_media_type = \"image/jpeg\"\n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": image_media_type,\n",
    "                    \"data\": image_data,\n",
    "                },\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\", max_tokens=2048, messages=messages\n",
    ")\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "\n",
    "def get_image_dict_from_url(image_url):\n",
    "    # Send a GET request to the image URL and retrieve the content\n",
    "    response = httpx.get(image_url)\n",
    "    image_content = response.content\n",
    "\n",
    "    # Determine the media type of the image based on the URL extension\n",
    "    # This is not a foolproof approach, but it generally works\n",
    "    image_extension = image_url.split(\".\")[-1].lower()\n",
    "    if image_extension == \"jpg\" or image_extension == \"jpeg\":\n",
    "        image_media_type = \"image/jpeg\"\n",
    "    elif image_extension == \"png\":\n",
    "        image_media_type = \"image/png\"\n",
    "    elif image_extension == \"gif\":\n",
    "        image_media_type = \"image/gif\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image format\")\n",
    "\n",
    "    # Encode the image content using base64\n",
    "    image_data = base64.b64encode(image_content).decode(\"utf-8\")\n",
    "\n",
    "    # Create the dictionary in the proper image block shape:\n",
    "    image_dict = {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": {\n",
    "            \"type\": \"base64\",\n",
    "            \"media_type\": image_media_type,\n",
    "            \"data\": image_data,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed35e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Rincon_fire_truck.png/1600px-Rincon_fire_truck.png\"\n",
    "url2 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Ornge_C-GYNP.jpg/1600px-Ornge_C-GYNP.jpg\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Image 1:\"},\n",
    "            get_image_dict_from_url(url1),\n",
    "            {\"type\": \"text\", \"text\": \"Image 2:\"},\n",
    "            get_image_dict_from_url(url2),\n",
    "            {\"type\": \"text\", \"text\": \"What do these images have in common?\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"anthropic.claude-haiku-4-5-20251001-v1:0\", max_tokens=2048, messages=messages\n",
    ")\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978fb06e",
   "metadata": {},
   "source": [
    "Example of prompt with tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069530b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b85f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            create_image_message(\"./people.png\"),\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You have perfect vision and pay great attention to detail which makes you an expert at counting objects in images. How many people are in this picture? Some of the people may be partially obscured or cut off in the image or may only have an arm visible. Please count people even if you can only see a single body part. Before providing the answer in <answer> tags, think step by step in <thinking> tags and analyze every part of the image.\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    max_tokens=300,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a874185",
   "metadata": {},
   "source": [
    "Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.messages.create(\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    max_tokens=1024,\n",
    "    betas=[\"structured-outputs-2025-11-13\"],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Extract the key information from this email: John Smith (john@example.com) is interested in our Enterprise plan and wants to schedule a demo for next Tuesday at 2pm.\",\n",
    "        }\n",
    "    ],\n",
    "    output_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"string\"},\n",
    "                \"email\": {\"type\": \"string\"},\n",
    "                \"plan_interest\": {\"type\": \"string\"},\n",
    "                \"demo_requested\": {\"type\": \"boolean\"},\n",
    "            },\n",
    "            \"required\": [\"name\", \"email\", \"plan_interest\", \"demo_requested\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd94efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8048db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"stop_reason: {response.stop_reason}\")\n",
    "print(f\"stop_sequence: {response.stop_sequence}\")\n",
    "print(f\"input_tokens: {response.usage.input_tokens}\")\n",
    "print(f\"output_tokens: {response.usage.output_tokens}\")\n",
    "print(f\"server_tool_use: {response.usage.server_tool_use}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
